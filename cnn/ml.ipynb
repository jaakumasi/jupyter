{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4273d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras import regularizers\n",
    "from keras.activations import relu\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_and_crop_face(image):\n",
    "    # Detect face in the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    cropped_faces = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cropped_faces.append(image[y:y+h, x:x+w])\n",
    "    return cropped_faces\n",
    "#     if len(faces) > 0:\n",
    "#         (x, y, w, h) = faces[0]\n",
    "#         face = image[y:y+h, x:x+w]\n",
    "#         return [face]\n",
    "#     return []\n",
    "\n",
    "dataset = '.\\lfw'\n",
    "images = []\n",
    "labels = []\n",
    "label_map = {} # maps names to indexes since numerical labels are required\n",
    "\n",
    "for folder_name in os.listdir(dataset):\n",
    "    # the folder name corresponds to the person's name\n",
    "    if folder_name not in label_map:\n",
    "        label_map[folder_name] = len(label_map)\n",
    "    label_idx = label_map[folder_name]\n",
    "    \n",
    "    for image_name in os.listdir(os.path.join(dataset, folder_name)):\n",
    "        image_path = os.path.join(dataset, folder_name, image_name)\n",
    "        image = cv.imread(image_path)\n",
    "        grayscaled_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)       \n",
    "        resized_image = cv.resize(grayscaled_image, (128, 128))\n",
    "        cropped_images = detect_and_crop_face(resized_image)\n",
    "        \n",
    "        for img in cropped_images:\n",
    "#             cv.imwrite(os.path.join('/users/jerome akumasi/desktop/cropped', f'{image_name}_{random.randint(0, 100000)}.jpg'), img)\n",
    "            images.append(img)\n",
    "            labels.append(label_idx)\n",
    "        \n",
    "            \n",
    "#         equalized_image = cv.equalizeHist(cropped_image)\n",
    "        \n",
    "#         images.append(resized_image)\n",
    "#         labels.append(label_idx)\n",
    "        \n",
    "print(images[0])\n",
    "    \n",
    "# images = np.array(images, dtype=np.float32)        \n",
    "        \n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "x_train = np.array(x_train, dtype=np.float32) / 255.0 # normalize\n",
    "# y_train = np.array(y_train, dtype=np.int32)\n",
    "# x_test  = np.array(x_test, dtype=np.float32) / 255.0  # normalize\n",
    "# y_test  = np.array(y_test, dtype=np.int32)\n",
    "\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    num_of_classes = len(label_map)\n",
    "    \n",
    "    inputs = keras.Input(shape=(128, 128, 1))\n",
    "    x = Conv2D(10, (2,2), padding='same', kernel_regularizer=regularizers.l2())(inputs) # conv 1\n",
    "    x = BatchNormalization()(x) # norm 1\n",
    "    x = relu(x) # activation 1\n",
    "    x = MaxPooling2D()(x) # pooling 1\n",
    "    \n",
    "    x = Conv2D(20, (2,2), padding='same', kernel_regularizer=regularizers.l2())(x) # conv 2\n",
    "    x = BatchNormalization()(x) # norm 2\n",
    "    x = relu(x) # activation 2\n",
    "    x = MaxPooling2D()(x) # pooling 2\n",
    "    \n",
    "    x = Conv2D(30, (2,2), padding='same', kernel_regularizer=regularizers.l2())(x) # conv 3\n",
    "    x = BatchNormalization()(x) # norm 3\n",
    "    x = relu(x) # activation 3\n",
    "    x = MaxPooling2D()(x) # pooling 3\n",
    "    \n",
    "    x = Conv2D(40, (2,2), padding='same', kernel_regularizer=regularizers.l2())(x) # conv 4\n",
    "    x = BatchNormalization()(x) # norm 4\n",
    "    x = relu(x) # activation 4\n",
    "    x = MaxPooling2D()(x) # pooling 4\n",
    "    \n",
    "    x = Flatten()(x) # flatten\n",
    "    x = Dense(64, activation='relu')(x) # dense 1\n",
    "    x = Dropout(0.5)(x) # 50% dropout\n",
    "    outputs = Dense(num_of_classes, activation='softmax')(x) # dense 2, outputs\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs) \n",
    "    return model\n",
    "\n",
    "\n",
    "model = cnn_model()\n",
    "\n",
    "loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(\n",
    "    loss=loss, \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "# model.fit(x_train, y_train, epochs=epochs, verbose=2)\n",
    "\n",
    "# model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n",
    "\n",
    "# keras.models.save_model(model, './model/recog.h5')\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
